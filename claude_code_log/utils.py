#!/usr/bin/env python3
"""Utility functions for message filtering and processing."""

from typing import Union, List, Dict, Tuple, Optional

from claude_code_log.cache import SessionCacheData
from .models import (
    ContentItem,
    TextContent,
    TranscriptEntry,
    UserTranscriptEntry,
    AssistantTranscriptEntry,
    SummaryTranscriptEntry,
    UsageInfo,
)


def is_system_message(text_content: str) -> bool:
    """Check if a message is a system message that should be filtered out."""
    system_message_patterns = [
        "Caveat: The messages below were generated by the user while running local commands. DO NOT respond to these messages or otherwise consider them in your response unless the user explicitly asks you to.",
        "[Request interrupted by user for tool use]",
        "<local-command-stdout>",
    ]

    return any(pattern in text_content for pattern in system_message_patterns)


def is_command_message(text_content: str) -> bool:
    """Check if a message contains command information that should be displayed."""
    return "<command-name>" in text_content and "<command-message>" in text_content


def is_local_command_output(text_content: str) -> bool:
    """Check if a message contains local command output."""
    return "<local-command-stdout>" in text_content


def should_skip_message(text_content: str) -> bool:
    """
    Determine if a message should be skipped in transcript rendering.

    This is the centralized logic for filtering out unwanted messages.
    """
    is_system = is_system_message(text_content)
    is_command = is_command_message(text_content)

    # Skip system messages that are not command messages
    return is_system and not is_command


def extract_init_command_description(text_content: str) -> str:
    """
    Extract a meaningful description from init command content.

    Returns a user-friendly description for init commands instead of raw XML.
    """
    if "<command-name>init" in text_content and "<command-contents>" in text_content:
        return "Claude Initializes Codebase Documentation Guide (/init command)"
    return text_content


def should_use_as_session_starter(text_content: str) -> bool:
    """
    Determine if a user message should be used as a session starter preview.

    This filters out system messages and most command messages, except for 'init' commands
    which are typically the start of a new session.
    """
    # Skip system messages
    if is_system_message(text_content):
        return False

    # Skip command messages except for 'init' commands
    if "<command-name>" in text_content:
        return "<command-name>init" in text_content

    return True


# Constants
FIRST_USER_MESSAGE_PREVIEW_LENGTH = 1000


def create_session_preview(text_content: str) -> str:
    """Create a truncated preview of first user message for session display.

    Args:
        text_content: The raw text content from the first user message

    Returns:
        A preview string, truncated to FIRST_USER_MESSAGE_PREVIEW_LENGTH with
        ellipsis if needed, and with init commands converted to friendly descriptions.
    """
    preview_content = extract_init_command_description(text_content)
    if len(preview_content) > FIRST_USER_MESSAGE_PREVIEW_LENGTH:
        return preview_content[:FIRST_USER_MESSAGE_PREVIEW_LENGTH] + "..."
    return preview_content


def extract_text_content_length(content: Union[str, List[ContentItem]]) -> int:
    """Get the length of text content for quick checks without full extraction."""
    if isinstance(content, str):
        return len(content.strip())

    # For list content, count only text items
    total_length = 0
    for item in content:
        # Only count TextContent items, skip tool/thinking/image items
        if isinstance(item, TextContent):
            total_length += len(item.text.strip())

    return total_length


def extract_working_directories(
    entries: List[TranscriptEntry] | List[SessionCacheData],
) -> List[str]:
    """Extract unique working directories from a list of entries.

    Ordered by timestamp (most recent first).

    Args:
        entries: List of entries to extract working directories from

    Returns:
        List of unique working directory paths found in the entries
    """
    working_directories: dict[str, str] = {}

    for entry in entries:
        cwd = getattr(entry, "cwd", None)
        if not cwd:
            continue

        # Get appropriate timestamp based on entry type
        if isinstance(entry, SessionCacheData):
            timestamp = entry.last_timestamp
        elif hasattr(entry, "timestamp"):
            timestamp = getattr(entry, "timestamp", "")
        else:
            timestamp = ""

        working_directories[cwd] = timestamp

    # Sort by timestamp (most recent first) and return just the paths
    sorted_dirs = sorted(working_directories.items(), key=lambda x: x[1], reverse=True)
    return [path for path, _ in sorted_dirs]


def map_summaries_to_sessions(
    entries: List[TranscriptEntry],
) -> Tuple[Dict[str, str], Dict[str, SummaryTranscriptEntry]]:
    """Map session summaries to their corresponding sessions.

    This function creates a mapping from session IDs to summaries by tracking
    message UUIDs and matching them with summary leafUuids.

    Args:
        entries: List of transcript entries containing messages and summaries

    Returns:
        A tuple of:
        - Dict mapping session_id to session summary text
        - Dict mapping session_id to the full SummaryTranscriptEntry object
    """
    # Build UUID to session ID mapping
    uuid_to_session: Dict[str, str] = {}
    uuid_to_session_backup: Dict[str, str] = {}

    for entry in entries:
        if isinstance(entry, (UserTranscriptEntry, AssistantTranscriptEntry)):
            # Prioritize assistant messages for mapping
            if isinstance(entry, AssistantTranscriptEntry):
                uuid_to_session[entry.uuid] = entry.sessionId
            else:
                # Use backup mapping for user messages
                uuid_to_session_backup[entry.uuid] = entry.sessionId

    # Map summaries to sessions
    session_summaries: Dict[str, str] = {}
    session_summary_entries: Dict[str, SummaryTranscriptEntry] = {}

    for entry in entries:
        if isinstance(entry, SummaryTranscriptEntry):
            # Try primary mapping first (assistant messages)
            session_id = uuid_to_session.get(entry.leafUuid)
            if not session_id:
                # Fall back to backup mapping (user messages)
                session_id = uuid_to_session_backup.get(entry.leafUuid)

            if session_id:
                session_summaries[session_id] = entry.summary
                session_summary_entries[session_id] = entry

    return session_summaries, session_summary_entries


def format_token_usage(
    input_tokens: int = 0,
    output_tokens: int = 0,
    cache_creation_tokens: int = 0,
    cache_read_tokens: int = 0,
) -> str:
    """Format token usage for display in a consistent way.

    Args:
        input_tokens: Number of input tokens
        output_tokens: Number of output tokens
        cache_creation_tokens: Number of cache creation tokens
        cache_read_tokens: Number of cache read tokens

    Returns:
        Formatted string like "Input: 100 | Output: 50 | Cache Creation: 25"
    """
    token_parts: List[str] = []
    if input_tokens > 0:
        token_parts.append(f"Input: {input_tokens}")
    if output_tokens > 0:
        token_parts.append(f"Output: {output_tokens}")
    if cache_creation_tokens > 0:
        token_parts.append(f"Cache Creation: {cache_creation_tokens}")
    if cache_read_tokens > 0:
        token_parts.append(f"Cache Read: {cache_read_tokens}")
    return " | ".join(token_parts) if token_parts else ""


def aggregate_token_usage(
    usage: Optional[UsageInfo],
    totals: Dict[str, int],
) -> None:
    """Aggregate token usage into running totals.

    Args:
        usage: UsageInfo object to aggregate
        totals: Dictionary with keys 'input', 'output', 'cache_creation', 'cache_read'
               that will be updated in place
    """
    if not usage:
        return

    totals["input"] += usage.input_tokens or 0
    totals["output"] += usage.output_tokens or 0
    if usage.cache_creation_input_tokens:
        totals["cache_creation"] += usage.cache_creation_input_tokens
    if usage.cache_read_input_tokens:
        totals["cache_read"] += usage.cache_read_input_tokens
